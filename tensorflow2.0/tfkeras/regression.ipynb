{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib 3.1.1\n",
      "numpy 1.16.0\n",
      "pandas 0.25.1\n",
      "sklearn 0.21.3\n",
      "tensorflow 2.0.0-beta0\n",
      "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys,time\n",
    "\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 8.32520000e+00,  4.10000000e+01,  6.98412698e+00,\n",
      "         1.02380952e+00,  3.22000000e+02,  2.55555556e+00,\n",
      "         3.78800000e+01, -1.22230000e+02],\n",
      "       [ 8.30140000e+00,  2.10000000e+01,  6.23813708e+00,\n",
      "         9.71880492e-01,  2.40100000e+03,  2.10984183e+00,\n",
      "         3.78600000e+01, -1.22220000e+02],\n",
      "       [ 7.25740000e+00,  5.20000000e+01,  8.28813559e+00,\n",
      "         1.07344633e+00,  4.96000000e+02,  2.80225989e+00,\n",
      "         3.78500000e+01, -1.22240000e+02],\n",
      "       [ 5.64310000e+00,  5.20000000e+01,  5.81735160e+00,\n",
      "         1.07305936e+00,  5.58000000e+02,  2.54794521e+00,\n",
      "         3.78500000e+01, -1.22250000e+02],\n",
      "       [ 3.84620000e+00,  5.20000000e+01,  6.28185328e+00,\n",
      "         1.08108108e+00,  5.65000000e+02,  2.18146718e+00,\n",
      "         3.78500000e+01, -1.22250000e+02]])\n",
      "array([4.526, 3.585, 3.521, 3.413, 3.422])\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(housing.data[0:5])\n",
    "pprint.pprint(housing.target[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all,x_test,y_train_all,y_test = train_test_split(\n",
    "    housing.data,housing.target,random_state = 7\n",
    ")\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(\n",
    "    x_train_all,y_train_all,random_state=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#归一化处理\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                270       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(30,activation='relu',input_shape=x_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 0.9148 - val_loss: 1.2442\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 1.6987 - val_loss: 1.3209\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 1.7724 - val_loss: 0.4830\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.4373 - val_loss: 0.4576\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3937 - val_loss: 0.3975\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3824 - val_loss: 0.4216\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3758 - val_loss: 0.3870\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3651 - val_loss: 0.3784\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3627 - val_loss: 0.3770\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3591 - val_loss: 0.3755\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3597 - val_loss: 0.3685\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3537 - val_loss: 0.3667\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3592 - val_loss: 0.3668\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3527 - val_loss: 0.3730\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3478 - val_loss: 0.3591\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3456 - val_loss: 0.3583\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3431 - val_loss: 0.3581\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3461 - val_loss: 0.3610\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3413 - val_loss: 0.3567\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3399 - val_loss: 0.3529\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3379 - val_loss: 0.3566\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3365 - val_loss: 0.3574\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3393 - val_loss: 0.3803\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3369 - val_loss: 0.3513\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3344 - val_loss: 0.3507\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3336 - val_loss: 0.3558\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4993 - val_loss: 0.3865\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3480 - val_loss: 0.3515\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3399 - val_loss: 0.3497\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3363 - val_loss: 0.3520\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3357 - val_loss: 0.3469\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3346 - val_loss: 0.3459\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3340 - val_loss: 0.3449\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3370 - val_loss: 0.3508\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3314 - val_loss: 0.3478\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3302 - val_loss: 0.3543\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3289 - val_loss: 0.3412\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3283 - val_loss: 0.3453\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3275 - val_loss: 0.3431\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3261 - val_loss: 0.3403\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3250 - val_loss: 0.5364\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4156 - val_loss: 0.3479\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3298 - val_loss: 0.3409\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3251 - val_loss: 0.3466\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3242 - val_loss: 0.3370\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3253 - val_loss: 0.3375\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3207 - val_loss: 0.3359\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3196 - val_loss: 0.3357\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3178 - val_loss: 0.3300\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3220 - val_loss: 0.3289\n",
      "Epoch 51/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3152 - val_loss: 0.3281\n",
      "Epoch 52/100\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3237 - val_loss: 0.3319\n",
      "Epoch 53/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3130 - val_loss: 0.3284\n",
      "Epoch 54/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3126 - val_loss: 0.3292\n",
      "Epoch 55/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3111 - val_loss: 0.3386\n",
      "Epoch 56/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3099 - val_loss: 0.3315\n",
      "Epoch 57/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3098 - val_loss: 0.3210\n",
      "Epoch 58/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3156 - val_loss: 0.3235\n",
      "Epoch 59/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3129 - val_loss: 0.3210\n",
      "Epoch 60/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3136 - val_loss: 0.3246\n",
      "Epoch 61/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3112 - val_loss: 0.3218\n",
      "Epoch 62/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3079 - val_loss: 0.3203\n",
      "Epoch 63/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3059 - val_loss: 0.3487\n",
      "Epoch 64/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3114 - val_loss: 0.3194\n",
      "Epoch 65/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3212 - val_loss: 0.3205\n",
      "Epoch 66/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3166 - val_loss: 0.3192\n",
      "Epoch 67/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3163 - val_loss: 0.3260\n",
      "Epoch 68/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3131 - val_loss: 0.3206\n",
      "Epoch 69/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3050 - val_loss: 0.3304\n",
      "Epoch 70/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3071 - val_loss: 0.3224\n",
      "Epoch 71/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3050 - val_loss: 0.3173\n",
      "Epoch 72/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3028 - val_loss: 0.3230\n",
      "Epoch 73/100\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.3038 - val_loss: 0.3548\n",
      "Epoch 74/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3061 - val_loss: 0.3161\n",
      "Epoch 75/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3046 - val_loss: 0.3170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3050 - val_loss: 0.3230\n",
      "Epoch 77/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3052 - val_loss: 0.3163\n",
      "Epoch 78/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3134 - val_loss: 0.3167\n",
      "Epoch 79/100\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.3019 - val_loss: 0.3130\n",
      "Epoch 80/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3054 - val_loss: 0.3172\n",
      "Epoch 81/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3011 - val_loss: 0.3130\n",
      "Epoch 82/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3009 - val_loss: 0.3149\n",
      "Epoch 83/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3006 - val_loss: 0.3191\n",
      "Epoch 84/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3003 - val_loss: 0.3202\n",
      "Epoch 85/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3030 - val_loss: 0.3156\n",
      "Epoch 86/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.2998 - val_loss: 0.3124\n",
      "Epoch 87/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.2990 - val_loss: 0.3143\n",
      "Epoch 88/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3030 - val_loss: 0.3123\n",
      "Epoch 89/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.2978 - val_loss: 0.3110\n",
      "Epoch 90/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.2974 - val_loss: 0.3132\n",
      "Epoch 91/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.2983 - val_loss: 0.3102\n",
      "Epoch 92/100\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.2974 - val_loss: 0.3116\n",
      "Epoch 93/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.3013 - val_loss: 0.3154\n",
      "Epoch 94/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3142 - val_loss: 0.3244\n",
      "Epoch 95/100\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.3110 - val_loss: 0.3172\n",
      "Epoch 96/100\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.2973 - val_loss: 0.3187\n",
      "Epoch 97/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3007 - val_loss: 0.3086\n",
      "Epoch 98/100\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.2968 - val_loss: 0.3067\n",
      "Epoch 99/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.2982 - val_loss: 0.3132\n",
      "Epoch 100/100\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.2966 - val_loss: 0.3144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f91bfb2470>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\",optimizer='sgd')\n",
    "model.fit(x_train_scaled,y_train,validation_data=(x_valid_scaled,y_valid),\n",
    "          epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
